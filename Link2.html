<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link href="https://fonts.googleapis.com/css2?family=Lobster&display=swap" rel="stylesheet">
    <style>
    h1 {
        text-decoration: underline;
      }
    p {
        font-family: 'Lobster', cursive;
    }
    
   
    </style>
</head>
<body style="background-color: rgb(96, 244, 244);">
    <img class="fakeimg" style="width: 1270px;"  height="550px" src="https://user-images.githubusercontent.com/90642400/135280926-f53cdf6c-3ffb-4d63-b31b-8e07d87213f4.jpg">
    <center>
    <h1 style="color:blue;">Multi Skilled AI</h1>
    </center>
    <p style="font-size: 25px" >Despite the immense progress in artificial intelligence in recent years,<br>AI and robots are still dumb in many ways,<br> especially when it comes to solving new problems or navigating unfamiliar environments.<br> They lack the human ability, found even in young children,<br> to learn how the world works and apply that general knowledge to new situations.<br></br>

        One promising approach to improving the skills of AI is to expand its senses;<br> currently AI with computer vision or audio recognition can sense things but cannot “talk”<br> about what it sees and hears using natural-language algorithms. But what if you combined these abilities in a single AI system?<br> Might these systems begin to gain human-like intelligence? Might a robot that can see, feel, hear,<br> and communicate be a more productive human assistant? Karen Hao explains how AIs with multiple senses will gain a greater understanding of the world around them,<br> achieving a much more flexible intelligence.
    </p>
   
       
    
    
</body>
</html> 
